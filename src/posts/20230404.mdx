---
id: "20230404"
slug: "/20230404"
title: "Language Models as Knowledge Bases?"
description: ""
author: "Vive Kang"
date: "2023-04-04"
image: ""
tags: ["NLP", "paper review"]

---
## Motivation & Introduction

Knowledge bases는 relational data를 다루는 효과적인 방식이긴 하지만 KB를 만들기 위해서는 실제 text에서  relational data를 추출해야 한다. 그 과정에서 복잡한 NLP pipeline이 필요한데 entity extraction, coreference resolution, entity linking, relation extraction 과정이 필요하다. 그리고 이 과정 중에 에러가 중간에 생기면 전체 pipeline에 영향을 미치게 되기도 하며, 각 단계마다 supervised data가 필요하다. 

KB 대신, 논문에서는 LM에 들어있는 relational data를 사용하고자 한다. 이렇게 LM을 사용하게 되면 schema 설계와 human annotation이 필요 없어지고 다양한 query를 사용할 수 있다는 장점이 있다.

LM의 잠재력을 고려했을 때, 논문에서는 ELMo나 BERT 같은 유명한 pre-trained LM에 이미 relational knowledge가 들어있다고 한다. 그리고 다음에 대해 궁금해한다.

- relational knowledge가 얼마나 들어 있는지?
- entity, commonsense, general QA 각각의 종류의 knowledge에 대해 얼마나 다른지?
- pre-trained LM(w\o fine-tuning)와 KB의 성능을 어떻게 비교할 것인지?

위 질문들에 답을 하기 위해 LAMA(LAnguage Model Anaylsis) probe를 소개한다. 그리고 pre-trained LM이 masked LM task를 잘 예측한다면 그에 대한 fact를 알고 있다고 생각한다. 예를 들어, "Dante was born in ___"이라는 masked task를 잘 예측한다면 (Dante, born-in, Florence) 같은 fact를 이미 알고 있다고 생각하는 것이다. 

## The LAMA Probe

pre-trained LM에 factual, commonsense knowledge가 들어있는지 테스트하기 위해 LAMA(LAnguage Model Analysis)를 소개한다. corpus of facts인 knowledge source를 제공하는데, 여기서 fact는 subject-relation-object triples이거나 question-answer pair로 구성된다. fact들을 cloze statement 형태로 바꾸어서 각 LM을 평가하는데, 마스킹 토큰을 찾는 최종 결과에서 ground truth token이 얼마나 높은 순위로 ranking 되는지에 대해 평가한다. 논문에서는 이 ground truth token을 높은 순위로 rank할수록 그 모델은 factual knowledge를 갖고 있다고 가정한다.

### Knowledge Sources

**Google-RE**

Wikipedia로부터 manually extract된 facts. 총 5개의 relation을 갖고 있지만 논문에서는 "place of birth", "date of birth", "place of death" 이 3가지만 사용한다. 나머지 두개는 multi-token으로 구성된 object를 주로 갖기 때문에 테스트하려는 환경에 맞지 않아서 제외했다. relation에 적절한 template을 manual하게 만들어 줬다(e.g. [S] was born in [O] for "place of birth").

**T-REx**

Wikidata triples의 일부로 구성되어 있다. 41개의 relation, relation 당 최대 1000개의 template을 manual하게 만들었다.

**ConceptNet**

ConceptNet은 multilingual knowledge base인데, 논문에서는 영어 파트만 사용하고 single-token object를 갖는 16개의 relation만 사용한다. 

**SQuAD**

305개의 context-insensitive한 question을 찾고 이 질문들을 직접 cloze-style 문장으로 만들어 줬다. 
예를 들어, "Who developed the theory of relativity?"에서 "The theory of relativity was developed by ___".

### Models

다음의 6가지 pre-trained case-sensitive LM을 비교한다.

- fairseq-fconv ($Fs)$
- Transformer-XL large ($Txl$)
- ELMo original ($Eb$)
- ELMo 5.5B ($E5B$)
- BERT-base ($Bb$)
- BERT-large ($Bl$)

unidirectional LM은 $t$ 위치의 토큰을 예측할 때 $t-1$까지의 토큰을 이용하고, ELMo는 $t$위치를 기준으로 양쪽을 각각 forward/backward로 이용하는 등 각 모델이 갖고 있는 자연스러운 방식으로 토큰을 예측하게끔 했다. 

### Baselines

**Freq**

subject-relation pair가 주어졌을 때 각 단어가 여기에 맞는 object로 얼마나 자주 등장하느냐에 따라 rank를 매긴다. 

**RE**

Relation Extraction(RE) 모델은 주어진 문장에서 relation triples를 뽑아낸다(LSTM + attention). 이 dataset을 이용해 RE는 triples의 knowledge graph(KG)를 구축한다. 테스트할 때, query에 대해 subject entity를 찾은 다음 모든 가능한 object를 RE의 confidence score를 기반으로 rank를 매긴다. 두 종류의 RE를 사용한다. 

- RE$_n$ : exact string matching entity linking
- RE$_o$ : exact string matching + oracle-based entity linking

**DrQA**

TF-IDF based information retriever + $k$개의 retrieve된 글에서 정답을 찾아내는 reading comprehension model. 정답이 single-token인 것만 사용했다.

### Metrics

정답 토큰이 rank에 따라 평가하는 rank-based metric를 사용하고 전체 relation에 대해 평균 값을 그 LM의 최종 결과로 계산했다. subject-relation pair에 대해 여러개의 object 정답이 있는 경우 하나를 제외하고 전부 제거해서 공평한 테스트가 되도록 했다. 

그리고 P@k(precision at k)를 사용한다(top k rank 안에 object가 있을 경우 1, 아닐 경우 0이다).

### Considerations

LAMA probe를 만들 때 여러 중요한 요소를 소개한다

**Manually Defined Templates**

object를 채워넣기 위한 template을 manual하게 만들다 보니 template에 따라 그 결과가 달라질 수 있다. 따라서 LM이 얼마나 knowledge를 알고 있는 지에 대한 lower bound를 측정하는 것이다.

**Single Token**

target으로 single token object만 사용하도록 제한했다. multi token을 decoding하려면 추가적인 parameter가 더해지게 되는데 이때문에 논문에서 측정하고자 하는 knowledge가 모호해진다.

**Object Slots**

triples에서 object 부분만 예측하도록 했는데, reverse relation을 통해서 어차피 subject도 예측할 수 있기 때문이다. relation은 single 토큰이 아닌 여러 토큰으로 종종 표현되고 multi token을 쉽게 예측할 수 있더라도 relation에 들어갈 단어는 다른 많은 단어로 표현이 되기 때문이다.

**Intersection of Vocabularies**

각 모델들은 서로 다른 vocabulary에 기반해서 학습되었다. LAMA probe의 성능에 vocabulary가 영향을 미치는데, vocabulary가 클수록 정답 토큰을 top rank 하기가 힘들어지는 경향이 있었다. 이런 이유로 21K의 case-sensitive token으로 구성된 vocabulary를 동일하게 사용했다. 이 vocabulary는 각 모델이 사용한 것의 intersection 부분을 모은 joint vocabulary이다.

## Results

![0](../blogImage/19-0.png)

**Google-RE**

BERT-base/large 모델이 다른 모델들에 비해 압도적으로 성능이 좋았다. 그러나 이 사실만 가지고 판단하기 힘든데, Google-RE가 결국 Wikipedia 기반의 데이터이고 BERT도 Wikipedia로 학습 되었기 때문이다.

**T-REx**

Google-RE가 fact 수도 적고 relation도 3개 밖에 안 되기 때문에 fact와 relation이 더 많은 T-REx로도 테스트했다. 그 결과 Google-RE에서와 거의 비슷했다. BERT는 1-1 relation에서 점수가 아주 높았고, N-M relation에서 점수가 낮았다. 

![1](../blogImage/19-1.png)

LM이 정답을 rank-1로 정확히 예측하지 않더라도 충분히 높은 순위로만 예측한다면 downstream model에서 그 knowledge를 학습할 수 있다. 위 figure는 mean P@k 그래프인데, BERT의 경우 top-10안에 정답이 들어있을 확률이 60%, top-100에는 80%나 되었다.

왜 BERT가 이렇게 좋은 성능을 보이는 지 알아보기 위해 P@1과 다른 metric들의 Pearson correlation coefficient를 계산해 보았다.

- Pearson correlation coefficient
    
    -1 ~ +1 사이의 값을 갖는 연속적인 두 변수 간의 linear relationship을 구하는 방법이다. +1이면 하나의 값이 증가하면 다른 하나도 증가한다는 의미이고 -1이면 반대로 감소한다는 의미이다. 0일 경우 두 변수는 상관관계가 없다는 뜻이다.
    

![2](../blogImage/19-2.png)

object가 언급된 횟수(OM)는 P@1과 양의 상관관계를 가졌고 subject가 언급된 횟수(SM)는 음의 상관관계를 가졌다. log probability of prediction(LPFP)은 큰 양의 상관관계를 가졌다. 따라서 BERT가 특정 예측 값을 높은 확률로 예측한다면 그 답은 웬만하면 맞다. subject와 object의 cosine similarity도 양의 상관관계를 가졌다. 

![3](../blogImage/19-3.png)

100개의 임의의 fact를 뽑고, fact 당 10개의 다른 query의 평균 rank distribution이다. BERT, ELMo-5.5B가 성능이 잘 나왔지만 이 모델들은 다른 모델들보다 Wikipedia 데이터를 많이 이용해 학습 되었다는 걸 기억해야 한다. 

**ConceptNet**

 ConceptNet은 Google-RE, T-REx와 비슷하게 BERT가 가장 성능이 좋았다.

**SQuAD**

LM들을 open-domain cloze-style QA에 대해 평가하고 DrQA와 비교했다. DrQA가 훨씬 성능이 좋았는데, pre-trained LM은 unsupervised data로 학습되었고, fine-tuning도 되지 않았고 IR system도 없기 때문에 그렇다고 말한다. 그러나 P@10에서 비교 했을 때, BERT-large 57.1, DrQA 63.5로 많이 좁혀졌다고 한다.

## Discussion and Conclusion

BERT-large 모델이 다른 LM들이나 심지어 supervised alternative들보다 더 knowledge를 많이 갖고 있었다. 여러 모델들 간의 비교에 목적을 두지 않고 기존의 pre-trained LM의 weight에 knowledge가 존재한다는 걸 보여주는 데 초점을 두었다. 

BERT의 성능이 좋은 이유가 많은 데이터를 학습했기 때문이라고 생각해서 relation extraction system에도 추가적인 데이터를 이용해봤지만 성능 상 큰 변화가 없었다. relation extraction은 성능을 높이기 힘들고 LM은 추가적인 dataset을 통해 학습시킬 수록 성능이 좋아지고 있기 때문에 text로부터 만들어내는 KB를 LM이 대체할 수 있을 거라고 생각한다.

---

피드백은 언제나 환영합니다. 잘못된 내용이 있으면 댓글로 피드백 부탁드립니다.
