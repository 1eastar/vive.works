---
id: "20230418"
slug: "/20230418"
title: "EDA: Easy Data Augmentation Techniques for Boosting Performance on Text Classification Tasks"
description: ""
author: "Vive Kang"
date: "2023-04-18"
image: ""
tags: ["NLP", "paper review"]

---
## Motivation & Introduction

text classification 분야에서 좋은 모습들을 보이고는 있지만, 이 좋은 성능은 보통 학습 데이터의 양이나 퀄리티에서 기인한 것이며 이런 학습 데이터를 모으는 일은 쉬운 일이 아니다. Automatic data augmentation 방법이 비전이나 음성 쪽에서 사용되고는 있지만 NLP 분야에서 일반화해서 사용하기에는 아직 연구가 덜 되었다.

이전에 여러 연구들이 있긴 했다. 영어 → 프랑스어 → 영어로 다시 번역을 하면서 새로운 데이터를 얻기도 했고 data noising이나 synonym replacement 같은 방법을 사용하기도 했지만 이런 방법들은 성능상의 이점보다 연산 과정에서의 비용이 더 컸다.

논문에서는 EDA(Easy Data Augmentation)이라 부르는 보편적인 data augmentation techniques을 소개한다.

## EDA

적은 데이터로 학습시킨 text classifier가 낮은 성능을 보인 것에서 시작하여, 비전에서 영감을 받은 여러 augmentation 기법들을 테스트했고 이것이 모델의 성능을 높인다는 걸 발견했다. EDA는 기존 training set에서 주어진 하나의 sentence에 대해 다음의 operation들 중 하나를 임의로 수행했다.

1. **Synonym Replacement(SR)**
stop word를 제외하고 sentence에서 $n$ words를 임의로 선택한다. 각 단어를 동의어들 중 하나로 바꾼다.
2. **Random Insertion(RI)**
문장에서 stop word가 아닌 단어의 동의어를 임의로 찾고 그 동의어를 문장의 임의의 위치에 넣는다. 이 작업을 $n$ 번 반복한다.
3. **Random Swap(RS)**
문장에서 임의의 두 단어의 위치를 바꾼다. $n$번 반복한다.
4. **Random Deletion(RD)**
확률 $p$를 통해 문장 내 각 단어를 임의로 제거한다

문장의 길이가 길수록(문장 내에 단어가 많을수록) 더 많은 noise를 갖게 될 수 있는데, 이걸 방지하기 위해 바뀌는 단어의 수($n$)을 SR, RI, RS마다 문장 길이 $l$에서 공식 $n=\alpha l$에 기반하여 다르게 정해주었다. 여기서 $\alpha$는 문장 내에서 바뀔 단어의 비율을 나타내는 parameter이다.

그리고 각각의 원래 문장에 대해 $n_{aug}$개의 augmentation 문장을 만들었다. 아래 표가 그 예시이다.

![0](../blogImage/29-0.png)

## Experimental Setup

EDA를 평가하기 위해 5개의 text classification task benchmark와 2개의 network 아키텍처를 사용했다.

### Benchmark Datasets

다음의 5가지 benchmark를 사용했다.

![1](../blogImage/29-1.png)

그리고 EDA가 작은 dataset에 더 많은 도움이 될 것이라고 생각했고 전체 training set에서 \{ 500, 2000, 5000, 전체 \} 개수의 임의의 subset을 선택했다.

### Text Classification Models

text classification에서 유명한 두가지 모델에서 실험했다. (1) LSTM-RNN, (2) CNN.

## Results

### EDA Makes Gains

RNN, CNN모델에 EDA를 사용했을 때와 안 했을 때 각각에 대한 결과를 나타낸 표이다.

![2](../blogImage/29-2.png)

전체 dataset을 사용했을 땐 0.8%, $N_{train}=500$ 일 때는 3.0%의 평균 성능 향상이 있었다.

### Training Set Sizing

datatset의 양이 적을수록 EDA의 효과가 뛰어나다는 걸 보였다. 

![3](../blogImage/29-3.png)

Figure 1-(e)에서 EDA를 사용했을 때와 안 했을 때의 큰 성능 차이를 볼 수 있고, 1-(f)에서 전체 dataset에 대한 평균적인 결과 값을 볼 수 있다. EDA를 사용하지 않고 전체 dataset을 사용했을 때 평균 88.3%의 accuracy를 보였고 50%의 dataset만 이용하고 EDA를 사용했을 때 88.6%로 전체 dataset을 사용한 것보다 뛰어난 결과를 보였다.

### Does EDA conserve true labels?

data augmentation을 하게 되면 data의 classification label은 그대로 유지되면서 데이터만 바뀐다. 그러나 input sentence가 많이 바뀌게 된다면 기존의 label 값이 더이상 적절하지 않을 수 있다. 따라서 EDA operation이 augmented sentence의 의미를 많이 바꾸는지를 확인해보았다. 먼저, augmentation 없이 RNN 모델을 pro-con classification task(PC)에 대해 학습시켰다. 그러고 test set의 각 문장에 대해 9개의 augmented sentence를 만들었다. 이렇게 만들어진 각 문장당 10개의 데이터에 대해 RNN output을 뽑아냈고 그 결과를 시각적으로 나타냈다.

![4](../blogImage/29-4.png)

그 결과 대체적으로 EDA로 augmented된 문장들도 label들도 기존 문장의 label을 유지했다는 걸 알 수 있었다.

### Ablation Study: EDA Decomposed

각 EDA operation의 영향에 대한 연구를 진행했다. Synonym Replacement(SR)은 이전 다른 연구에서 소개된 적 있지만, 나머지 3가지 operation은 아니다. 이전 연구에 소개되었듯 EDA의 효과가 SR 때문인 거 아니냐 라고 생각할 수 있기에, 각 operation에 대해 독립적으로 연구를 했다. 4개의 operation에 대해 augmentation parameter인 $\alpha$=\{0.05, 0.1, 0.2, 0.3, 0.4, 0.5\} 값을 다르게 해가며 테스트를 진행했다.

![5](../blogImage/29-5.png)

결과적으로 4가지 operation 모두 다 성능 향상에 도움이 되었다.

SR에서 $\alpha$값이 작을 때 성능 향상에 도움이 되었지만 클 때는 문장에서 너무 많은 단어가 변경되어서 오히려 성능이 떨어졌다. 

RI에서는 $\alpha$값에 따라 큰 변화 없이 안정적으로 성능 향상을 볼 수 있었는데, 기존 단어의 상대적인 순서가 유지되었기 때문이라고 생각한다.

RS에서는 $\alpha$≤0.2 구간에서 높은 성능 향상을 보였고 그 이후에는 너무 많은 swapping으로 인해 성능 향상 폭이 감소했다.

RD는 $\alpha$값이 작을 때 가장 많은 성능 향상을 보였지만 $\alpha$값이 클수록 급격하게 감소했다. 문장 내 단어가 많이 지워지게 되었을 때를 생각하면 당연한 결과이다.

특히 데이터 양이 적을 때 성능이 많이 개선됨을 볼 수 있었고 전반적으로 $\alpha$=0.1 일 때가 "sweet spot"이었다.

### How much augmentation?

다음 step으로는 한 문장당 몇개의 문장을 augmentation할지 결정하는 것이다.

![6](../blogImage/29-6.png)

적은 training set에서는 overfitting될 가능성이 높기 때문에 많은 문장을 augmentation하는 것이 성능 향상에 더 도움이 되었다. 많은 training set에서는 4개 이상의 augmented sentence를 만드는 건 도움이 되지 못했다. 따라서 training set 양에 따라 다음과 같은 paramter들을 추천한다.

![7](../blogImage/29-7.png)

## Discussion and Limitation

논문에서는 "how can we generate sentences for augmentation without changing their true labels?" 에 초점을 맞추어 간단한 operation들을 소개했다. EDA가 go-to augmentation method가 되길 원하는 것이 아니라 이 과정에서 있었던 일련의 생각과 과정들이 새로운 data augmentation 접근법으로 나아가는 힌트가 되었으면 한다.

EDA의 한계점으로는 먼저 데이터 양이 충분할 경우에는 성능 향상이 미미할 수 있다. 앞서 5개의 dataset에서 테스트했을 때 전체 dataset으로 테스트한 경우 1% 미만의 성능 향상을 얻었다. 그리고 데이터 양이 적을 때 성능 향상이 꽤 되긴 했지만 pre-trained 모델을 사용할 경우 성능 향상이 거의 없었다. 마지막으로 5개의 benchmark dataset을 사용해 평가했지만 data augmentation을 다룬 다른 연구들에서는 다른 모델과 dataset을 사용하고 있기에 related work와의 비교는 크게 의미 없어 보인다.

## Conclusion

간단한 data augmentation operation이 text classification task의 성능을 향상시킬 수 있음을 보였다. 때로는 그 정도가 미미하지만 데이터 양이 적을 경우 상당한 성능 향상과 overfitting 감소 효과를 입증했다.

---

피드백은 언제나 환영합니다. 잘못된 내용이 있으면 댓글로 피드백 부탁드립니다.
