---
id: "20230313"
slug: "/20230313"
title: "What Does BERT Look At? An Analysis of BERT’s Attention"
description: ""
author: "Vive Kang"
date: "2023-03-13"
image: ""
tags: ["NLP", "paper review"]

---

### Motivations

pre-training된 LM을 fine-tuning을 통해 task에 이용하면 높은 성능을 보이지만, 우리는 정확히 왜 성능이 높아지는 지 알지 못한다. pre-training을 통해 모델이 언어 구조를 학습한다고 하는데, 정확히 어떤 언어적인 특성을 학습하는 걸까?

Attention 메커니즘을 이용하는 어느 모델이든 상관없지만 논문에서는 Base BERT(N=12, H=12)를 통해 분석해보려 한다.

### Surface-level Patterns in Attention

![figure 1](../blogImage/5-figure1.png)

**Relative Position**

각 토큰은 자기에게 어텐션하기 보다는 직전이나 직후에 나오는 토큰에 더 어텐션했다. 특히, 앞쪽에 있는 attention layer에서 그랬다. 한 attention layer 내에서 평균적으로 4개의 head가 직전의 토큰에 어텐션하고, 평균적으로 5개의 head에서 바로 다음 토큰에 어텐션했다.

**Attending to Separator Tokens**

![figure 2](../blogImage/5-figure2.png)

위쪽 그래프를 보면 5~10 layer에서는 [SEP] 토큰에 절반 이상이 어텐션한다.

이에 대해, 처음에는 [SEP] 토큰이 해당 segment-level의 정보를 담고 있기 때문이라고 생각했다. 이를 뒷받침하기 위해, [SEP] 토큰이 해당 segment의 전체 부분에 어텐션하기를 기대했으나, 두번째 그래프에서 보듯이 [SEP] 토큰은 90% 이상 [SEP] 토큰을 어텐션했다.

![figure 3](../blogImage/5-figure3.png)

위 그래프를 보면 목적어-동사 같은 특정 관계에 어텐션이 걸리는 걸 볼 수 있는데, 그것을 제외하고 나머지는 대부분 [SEP] 토큰을 어텐션한다. 이걸 볼 때, [SEP] 토큰에 걸린 어텐션들은 아무 의미 없는 것 같다.(no-op)

![figure 4](../blogImage/5-figure4.png)

추가로, 어텐션의 변화가 최종 output에 얼마나 영향을 끼치는 지 확인해보았다. y축은 MLM loss를 어텐션 weight로 미분한 값의 평균을 의미하는데, 이를 통해 [SEP] 토큰은 최종 output에도 크게 영향을 미치지 않는 것을 알 수 있었다.

**Focused vs Broad Attention**

어텐션 head들이 일부 몇 개의 토큰에만 주로 어텐션하는지 아니면 여러 토큰에 고르게 어텐션하는지 확인해보았다.

![figure 5](../blogImage/5-figure5.png)

여기서, 앞쪽 layer일수록 고르게 어텐션하는 걸 알 수 있고, 이 경우 output은 문장 안의 토큰들에 대한 bag-of-vectors가 된다.

### Probing Individual Attention Heads

개별 어텐션 head들이 언어의 어떤 부분을 학습하는 지 알기 위해 조사해보았다. 특히, dependency parsing같은 task의 labeled data에 대한 어텐션 head들을 평가했다.

**Method**

어텐션 head들을 word-level에서 평가하기 위해, BPE를 통해 토큰화되어있는 토큰을 word 단위로 매핑해주는 작업을 했다.

토큰A가 단어B를 split-up한 토큰B1, B2를 어텐션할 때, 토큰B1, B2의 어텐션의 합을 단어B의 어텐션으로 매핑해주었고,

반대로 단어A를 split-up한 토큰A1, A2에서 토큰B를 어텐션할 때, 해당 어텐션의 평균 값을 단어B의 어텐션으로 매핑해주었다.

**Dependency Syntax**

dependency parsing을 통해 dependent와 head로 구분하고 그 관계를 예측한다. dependent → head 로의 어텐션과, head → dependent로의 어텐션 둘 다 평가했다. 몇몇 dependency 관계는 예측하기 간단했는데, 예를 들어, 명사의 한정사(determiner)는 주로 명사의 바로 앞에 나타났다.

![table 1](../blogImage/5-table1.png)

위 테이블은 각 관계 별로 가장 예측을 잘하는 head와 그 정확도를 나타낸다. 전반적으로 모든 관계에 대해 잘 예측하는 head는 없었지만, 각 어텐션 head마다 잘 파악하는 관계가 존재함을 알 수 있다. 

또한, 어텐션이 dependent 단어에서 head 단어로는 많이 향하는 반면 그 반대는 그렇지 않았는데, 이는 dependent : head = N : 1의 관계이기 때문이라고 설명한다.

![figure 6](../blogImage/5-figure6.png)

**Coreference Resolution**

지금까지는 어텐션 head의 syntax 측면에 대해 다루었는데, 이제 좀 더 어려운 sementic한 측면에서 coreference resolution task를 이용해 평가해보려 한다.

특히, antecedent 정확도를 평가해본다. 즉, BERT를 이용해 task를 처리하는 과정에서 각 어텐션 head들에 대해, coreferent mention의 head word가 자신의 antecedent에게 가장 많을 어텐션주는 비율을 확인하려고 한다.

여기서는 antecedent를 선택하는 다른 3가지 baseline들과 비교해보았다.

1. 가장 가까운 다른 mention을 선택
2. 같은 head word를 갖는 가장 가까운 다른 mention을 선택
3. ruled-based에 따라 선택. 즉, 다음 우선순위를 먼저 만족하는 가장 가까운 mention을 선택. 
    1. full string match
    2. head word match
    3. number/gender/person match
    4. all other mentions

결과는 다음과 같다.

![table 2](../blogImage/5-table2.png)

BERT의 어텐션 head 중 하나(Head 5-4)는 Rule-based system에 가까운 성능을 보였다. 

특히, 명사 류(nominal)의 mention에서 좋은 성능을 보였는데, 동의어들 간의 미세한 차이를 잡아낼 수 있었기 때문인 것 같다고 한다. 

### Probing Attention Head Combinations

input 단어에 대해서, classifier는 문장 내의 전체 단어들에 대한 확률 분포를 출력한다. 확률 분포는 문장 내의 다른 단어들이 현재 단어의 syntactic head일 확률을 나타낸다.

다음 3개의 baseline과 Attention-Only probe, Attention-and-Words probe를 비교했다.

1. right-branching baseline : head가 항상 dependent의 오른쪽에 있다고 예측하는 것
2. dependent와 head 후보들의 GloVe embedding과 각 단어 사이의 거리를 입력받는 simple one-hidden-layer network
3. Attention-and-Words probe와 동일. pre-trained word/positional embedding을 제외하고 다른 weight들은 랜덤하게 초기화된 상태.

![table 3](../blogImage/5-table3.png)

Attn + GloVe의 성능이 가장 높게 나왔는데, 이는 BERT의 attention map이 영어 syntax 표현을 꽤 잘 한다는 것을 나타낸다.

완벽한 비교 대상은 아니지만, Hewitt and Manining(2019)의 structural probe와 비교해보았다. Attn + GloVe probing classifier의 점수와 해당 모델의 점수가 비슷한 이유는 BERT의 vector representations에서의 syntactic 정보가 attention map에서 얻을 수 있는 정보 이상으로는 존재하지 않음을 시사한다.

### Clustering Attention Heads

같은 어텐션 layer에 있는 head들은 얼마나 유사할까? 어텐션 head들 간에 눈에 띄는 클러스터링이 가능할까?

어텐션 head 간의 거리를 계산해 비교해보았다. head $H_i$와 $H_j$ 사이의 거리는 다음과 같이 표현된다.

$$
\sum_{token\in data}JS(H_i(token),H_j(token))
$$

JS: [Jensen-Shannon Divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)

![figure 7](../blogImage/5-figure7.png)

12개 layer 각각의 head들, 총 144개의 어텐션 head간의 거리를 2차원으로 나타낸 이미지이다. 위쪽 그림은 유사한 행동을 하는 head끼리 같은 표시를 해두었고, 아래쪽 그림에는 같은 layer에 속한 head끼리 표시를 해둔 것이다. 이를 볼 때, 전반적으로 같은 layer에 위한 head는 유사한 행동을 하는 것으로 보인다.

### Conclusion

최근 대다수의 NLP 모델 분석 연구들은 vector representation이나 output을 조사하는 데 초점이 맞춰져 있지만, 이 논문에서는 많은 양의 언어적 정보들이 hidden state나 attention map에 포함되어 있다는 것을 보여줬다. 그리고 attention map에 대한 연구가 더 필요하다고 생각한다.

---

피드백은 언제나 환영합니다. 잘못된 내용이 있으면 댓글로 피드백 부탁드립니다.
